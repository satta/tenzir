"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4360],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>u});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var p=n.createContext({}),l=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=l(e.components);return n.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,p=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=l(a),u=o,h=c["".concat(p,".").concat(u)]||c[u]||m[u]||r;return a?n.createElement(h,i(i({ref:t},d),{},{components:a})):n.createElement(h,i({ref:t},d))}));function u(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=c;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var l=2;l<r;l++)i[l]=a[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},58913:(e,t,a)=>{a.d(t,{ZP:()=>i});var n=a(87462),o=(a(67294),a(3905));const r={toc:[]};function i(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},r,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("admonition",{title:"Commercial Plugin",type:"note"},(0,o.kt)("p",{parentName:"admonition"},"This feature is available as commercial ",(0,o.kt)("a",{parentName:"p",href:"/docs/understand-vast/architecture/plugins"},"plugin")," that runs on top\nopen-source VAST. Please ",(0,o.kt)("a",{parentName:"p",href:"https://tenzir.com/contact-us"},"contact us")," if you'd like to try it out.")))}i.isMDXComponent=!0},52894:(e,t,a)=>{a.d(t,{ZP:()=>i});var n=a(87462),o=(a(67294),a(3905));const r={toc:[]};function i(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},r,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("admonition",{title:"Missing Documentation",type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"This part of the documentation is not yet written. Stay tuned.")))}i.isMDXComponent=!0},4035:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>p,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>m});var n=a(87462),o=(a(67294),a(3905)),r=a(58913),i=a(52894);const s={},p="Ingest",l={unversionedId:"use-vast/ingest/README",id:"use-vast/ingest/README",title:"Ingest",description:"Sending data to VAST (aka ingesting) involves spinning up a VAST client",source:"@site/docs/use-vast/ingest/README.md",sourceDirName:"use-vast/ingest",slug:"/use-vast/ingest/",permalink:"/docs/use-vast/ingest/",draft:!1,editUrl:"https://github.com/tenzir/vast/tree/master/web/docs/use-vast/ingest/README.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Run",permalink:"/docs/use-vast/run/"},next:{title:"Query",permalink:"/docs/use-vast/query/"}},d={},m=[{value:"Choose an import format",id:"choose-an-import-format",level:2},{value:"JSON",id:"json",level:3},{value:"CSV",id:"csv",level:3},{value:"Zeek",id:"zeek",level:3},{value:"Broker",id:"broker",level:4},{value:"Suricata",id:"suricata",level:3},{value:"NetFlow",id:"netflow",level:3},{value:"PCAP",id:"pcap",level:3},{value:"Real-World Traffic Replay",id:"real-world-traffic-replay",level:4},{value:"Flow Management",id:"flow-management",level:4},{value:"Argus",id:"argus",level:3},{value:"Read network data",id:"read-network-data",level:4},{value:"Convert Argus to CSV",id:"convert-argus-to-csv",level:4},{value:"Ingest Argus CSV",id:"ingest-argus-csv",level:4},{value:"Discard events from a data source",id:"discard-events-from-a-data-source",level:2},{value:"Infer a schema automatically",id:"infer-a-schema-automatically",level:2},{value:"Write a schema manually",id:"write-a-schema-manually",level:2},{value:"Map events to schemas",id:"map-events-to-schemas",level:2}],c={toc:m};function u(e){let{components:t,...s}=e;return(0,o.kt)("wrapper",(0,n.Z)({},c,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"ingest"},"Ingest"),(0,o.kt)("p",null,"Sending data to VAST (aka ",(0,o.kt)("em",{parentName:"p"},"ingesting"),") involves spinning up a VAST client\nthat parses and ships the data to a ",(0,o.kt)("a",{parentName:"p",href:"/docs/use-vast/run"},"VAST server"),":"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Ingest process",src:a(22596).Z+"#gh-light-mode-only",width:"2001",height:"720"}),"\n",(0,o.kt)("img",{alt:"Ingest process",src:a(14185).Z+"#gh-dark-mode-only",width:"2001",height:"720"})),(0,o.kt)("p",null,"VAST first acquires data through a ",(0,o.kt)("em",{parentName:"p"},"carrier")," that represents the data transport\nmedium. This typically involves I/O and has the effect of slicing the data into\nchunks of bytes. Thereafter, the ",(0,o.kt)("em",{parentName:"p"},"format")," determines how to parse the bytes into\nstructured events. On the VAST server, a partition builder (1) creates\nsketches for accelerating querying, and (2) creates a ",(0,o.kt)("em",{parentName:"p"},"store")," instance by\ntransforming the in-memory Arrow representation into an on-disk format, e.g.,\nParquet."),(0,o.kt)("p",null,"Loading and parsing take place in a separate VAST client to facilitate\nhorizontal scaling. The ",(0,o.kt)("inlineCode",{parentName:"p"},"import")," command creates a client for precisly this\ntask."),(0,o.kt)("p",null,"At the server, there exists one partition builder per schema. After a\npartition builder has reached a maximum number of events or reached a timeout,\nit sends the partition to the catalog to register it."),(0,o.kt)("admonition",{title:"Lakehouse Architecture",type:"note"},(0,o.kt)("p",{parentName:"admonition"},"VAST uses open standards for data in motion (",(0,o.kt)("a",{parentName:"p",href:"https://arrow.apache.org"},"Arrow"),")\nand data at rest (",(0,o.kt)("a",{parentName:"p",href:"https://parquet.apache.org/"},"Parquet"),"). You only ETL data\nonce to a destination of your choice. In that sense, VAST resembles a ",(0,o.kt)("a",{parentName:"p",href:"http://www.cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf"},"lakehouse\narchitecture"),". Think of the above pipeline as a chain of\nindependently operating microservices, each of which can be scaled\nindependently. The ",(0,o.kt)("a",{parentName:"p",href:"/docs/understand-vast/architecture/actor-model/"},"actor\nmodel")," architecture of\nVAST enables this naturally.")),(0,o.kt)("p",null,"The following discussion assumes that you ",(0,o.kt)("a",{parentName:"p",href:"/docs/use-vast/run"},"set up a VAST\nserver")," listening at ",(0,o.kt)("inlineCode",{parentName:"p"},"localhost:42000"),"."),(0,o.kt)("h2",{id:"choose-an-import-format"},"Choose an import format"),(0,o.kt)("p",null,"The ",(0,o.kt)("em",{parentName:"p"},"format")," defines the encoding of data. ASCII formats include JSON, CSV, or\ntool-specific data encodings like Zeek TSV. Examples for binary formats are\nPCAP and NetFlow."),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"import")," command reads data from file or standard input and takes a\nconcrete format as sub-command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import [options] <format> [options] [expr]\n")),(0,o.kt)("p",null,"For example, to import a file in JSON, use the ",(0,o.kt)("inlineCode",{parentName:"p"},"json")," format:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import json < data.json\n")),(0,o.kt)("p",null,"To see a list of available import formats, run ",(0,o.kt)("inlineCode",{parentName:"p"},"vast import help"),". To see the\nhelp for a specific format, run ",(0,o.kt)("inlineCode",{parentName:"p"},"vast import <format> help"),"."),(0,o.kt)("h3",{id:"json"},"JSON"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"json")," import format consumes ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON"},"line-delimited\nJSON")," objects\naccording to a specified schema. That is, one line corresponds to one event. The\nobject field names correspond to record field names."),(0,o.kt)("p",null,"JSON can express only a subset VAST's data model. For example, VAST has\nfirst-class support for IP addresses but they are strings in JSON. To get the\nmost out of your data and retain domain semantics, ",(0,o.kt)("a",{parentName:"p",href:"#provide-a-schema-for-unknown-types"},"define a schema for your\nJSON objects"),"."),(0,o.kt)("p",null,"Consider the this example JSON file ",(0,o.kt)("inlineCode",{parentName:"p"},"data.json"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{"ts":"2011-08-15T03:36:16.748830Z","uid":"CKmcUPexVMCAAkl6h","id.orig_h":"210.87.254.81","id.orig_p":3,"id.resp_h":"147.32.84.165","id.resp_p":1,"proto":"icmp","conn_state":"OTH","missed_bytes":0,"orig_pkts":1,"orig_ip_bytes":56,"resp_pkts":0,"resp_ip_bytes":0,"tunnel_parents":[]}\n{"ts":"2011-08-15T03:37:11.992151Z","uid":"CTluup1eVngpaS6e2i","id.orig_h":"147.32.84.165","id.orig_p":3923,"id.resp_h":"218.108.143.87","id.resp_p":22,"proto":"tcp","duration":3.006088,"orig_bytes":0,"resp_bytes":0,"conn_state":"S0","missed_bytes":0,"history":"S","orig_pkts":4,"orig_ip_bytes":192,"resp_pkts":0,"resp_ip_bytes":0,"tunnel_parents":[]}\n{"ts":"2011-08-15T03:37:12.593013Z","uid":"C4KKBn3pbBOEm8XWOk","id.orig_h":"147.32.84.165","id.orig_p":3924,"id.resp_h":"218.108.189.111","id.resp_p":22,"proto":"tcp","duration":3.005948,"orig_bytes":0,"resp_bytes":0,"conn_state":"S0","missed_bytes":0,"history":"S","orig_pkts":4,"orig_ip_bytes":192,"resp_pkts":0,"resp_ip_bytes":0,"tunnel_parents":[]}\n')),(0,o.kt)("p",null,"Import this file by specifying the schema ",(0,o.kt)("inlineCode",{parentName:"p"},"zeek.conn")," that ships with VAST:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import --type=zeek.conn json < data.json\n")),(0,o.kt)("p",null,"Passing a schema type via ",(0,o.kt)("inlineCode",{parentName:"p"},"--type")," is necessary because the NDJSON objects are\njust a collection of fields. VAST cannot know how to name the corresponding\ntable without an external hint. See the section on ",(0,o.kt)("a",{parentName:"p",href:"#map-events-to-schemas"},"mapping events to\nschemas")," for details."),(0,o.kt)("h3",{id:"csv"},"CSV"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"import csv")," command imports ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Comma-separated_values"},"comma-separated\nvalues (CSV)")," in tabular\nform. The first line in a CSV file must contain a header that describes the\nfield names. The remaining lines contain concrete values. Except for the header,\none line corresponds to one event."),(0,o.kt)("p",null,"Ingesting CSV is similar to ",(0,o.kt)("a",{parentName:"p",href:"#JSON"},"ingesting JSON"),". It is also necessary to\n",(0,o.kt)("a",{parentName:"p",href:"#map-events-to-schemas"},"select a layout")," via ",(0,o.kt)("inlineCode",{parentName:"p"},"--type")," whose field names\ncorrespond to the CSV header field names."),(0,o.kt)("p",null,"For a real-world example of ingesting CSV, take a look a the section covering\n",(0,o.kt)("a",{parentName:"p",href:"#argus"},"argus")," below."),(0,o.kt)("h3",{id:"zeek"},"Zeek"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"import zeek")," command consumes ",(0,o.kt)("a",{parentName:"p",href:"https://zeek.org"},"Zeek")," logs in\ntab-separated value (TSV) style, and the ",(0,o.kt)("inlineCode",{parentName:"p"},"import zeek-json")," command consumes\nZeek logs as ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON"},"line-delimited\nJSON")," objects\nas produced by the\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/corelight/json-streaming-logs"},"json-streaming-logs")," package.\nUnlike stock Zeek JSON logs, where one file contains exactly one log type, the\nstreaming format contains different log event types multiplexed in a single\nstream and uses an additional ",(0,o.kt)("inlineCode",{parentName:"p"},"_path")," field to disambiguate the log type. For\nstock Zeek JSON logs, use the existing ",(0,o.kt)("inlineCode",{parentName:"p"},"import json")," with the ",(0,o.kt)("inlineCode",{parentName:"p"},"--type")," option to\nspecify the log type. You do not need to specify a type for Zeek TSV, because\nVAST can infer the type from ",(0,o.kt)("inlineCode",{parentName:"p"},"#path")," comment."),(0,o.kt)("p",null,"Here's an example of a typical Zeek ",(0,o.kt)("inlineCode",{parentName:"p"},"conn.log")," in TSV form:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"#separator \\x09\n#set_separator  ,\n#empty_field  (empty)\n#unset_field  -\n#path conn\n#open 2014-05-23-18-02-04\n#fields ts  uid id.orig_h id.orig_p id.resp_h id.resp_p proto service duration  \u2026orig_bytes resp_bytes  conn_state  local_orig  missed_bytes  history orig_pkts \u2026orig_ip_bytes  resp_pkts resp_ip_bytes tunnel_parents\n#types  time  string  addr  port  addr  port  enum  string  interval  count coun\u2026t  string  bool  count string  count count count count table[string]\n1258531221.486539 Pii6cUUq1v4 192.168.1.102 68  192.168.1.1 67  udp - 0.163820  \u2026301  300 SF  - 0 Dd  1 329 1 328 (empty)\n1258531680.237254 nkCxlvNN8pi 192.168.1.103 137 192.168.1.255 137 udp dns 3.7801\u202625 350 0 S0  - 0 D 7 546 0 0 (empty)\n1258531693.816224 9VdICMMnxQ7 192.168.1.102 137 192.168.1.255 137 udp dns 3.7486\u202647 350 0 S0  - 0 D 7 546 0 0 (empty)\n1258531635.800933 bEgBnkI31Vf 192.168.1.103 138 192.168.1.255 138 udp - 46.72538\u20260  560 0 S0  - 0 D 3 644 0 0 (empty)\n1258531693.825212 Ol4qkvXOksc 192.168.1.102 138 192.168.1.255 138 udp - 2.248589\u2026  348  0 S0  - 0 D 2 404 0 0 (empty)\n1258531803.872834 kmnBNBtl96d 192.168.1.104 137 192.168.1.255 137 udp dns 3.7488\u202693 350 0 S0  - 0 D 7 546 0 0 (empty)\n1258531747.077012 CFIX6YVTFp2 192.168.1.104 138 192.168.1.255 138 udp - 59.05289\u20268  549 0 S0  - 0 D 3 633 0 0 (empty)\n1258531924.321413 KlF6tbPUSQ1 192.168.1.103 68  192.168.1.1 67  udp - 0.044779  \u2026303  300 SF  - 0 Dd  1 331 1 328 (empty)\n1258531939.613071 tP3DM6npTdj 192.168.1.102 138 192.168.1.255 138 udp - - - - S0\u2026  -  0 D 1 229 0 0 (empty)\n1258532046.693816 Jb4jIDToo77 192.168.1.104 68  192.168.1.1 67  udp - 0.002103  \u2026311  300 SF  - 0 Dd  1 339 1 328 (empty)\n1258532143.457078 xvWLhxgUmj5 192.168.1.102 1170  192.168.1.1 53  udp dns 0.0685\u202611 36  215 SF  - 0 Dd  1 64  1 243 (empty)\n1258532203.657268 feNcvrZfDbf 192.168.1.104 1174  192.168.1.1 53  udp dns 0.1709\u202662 36  215 SF  - 0 Dd  1 64  1 243 (empty)\n1258532331.365294 aLsTcZJHAwa 192.168.1.1 5353  224.0.0.251 5353  udp dns 0.1003\u202681 273 0 S0  - 0 D 2 329 0 0 (empty)\n")),(0,o.kt)("p",null,"You can import this log as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import zeek < conn.log\n")),(0,o.kt)("p",null,"When Zeek ",(0,o.kt)("a",{parentName:"p",href:"https://docs.zeek.org/en/stable/frameworks/logging.html#rotation"},"rotates\nlogs"),", it\nproduces compressed batches of ",(0,o.kt)("inlineCode",{parentName:"p"},"*.tar.gz")," regularly. If log freshness is not a\npriority, you could trigger an ad-hoc ingestion for every compressed\nbatch of Zeek logs:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"gunzip -c *.gz | vast import zeek\n")),(0,o.kt)("h4",{id:"broker"},"Broker"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"broker")," import command ingests events via Zeek's\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/zeek/broker"},"Broker")," communication library."),(0,o.kt)("p",null,"Broker provides a topic-based publish-subscribe communication layer and\nstandardized data model to interact with the Zeek ecosystem. Using the ",(0,o.kt)("inlineCode",{parentName:"p"},"broker"),"\nreader, VAST can transparently establish a connection to Zeek and subscribe log\nevents. Letting Zeek send events directly to VAST cuts out the operational\nhassles of going through file-based logs."),(0,o.kt)("p",null,"To connect to a Zeek instance, run the ",(0,o.kt)("inlineCode",{parentName:"p"},"broker")," command without arguments:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"# Spawn a Broker endpoint, connect to localhost:9999/tcp, and subscribe\n# to the topic `zeek/logs/` to acquire Zeek logs.\nvast import broker\n")),(0,o.kt)("p",null,"Logs should now flow from Zeek to VAST, assuming that Zeek has the following\ndefault settings:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The script variable ",(0,o.kt)("inlineCode",{parentName:"li"},"Broker::default_listen_address")," is set to ",(0,o.kt)("inlineCode",{parentName:"li"},"127.0.0.1"),".\nZeek populates this variable with the value from the environment variable\n",(0,o.kt)("inlineCode",{parentName:"li"},"ZEEK_DEFAULT_LISTEN_ADDRESS"),", which defaults to ",(0,o.kt)("inlineCode",{parentName:"li"},"127.0.0.1"),"."),(0,o.kt)("li",{parentName:"ul"},"The script variable ",(0,o.kt)("inlineCode",{parentName:"li"},"Broker::default_port")," is set to ",(0,o.kt)("inlineCode",{parentName:"li"},"9999/tcp"),"."),(0,o.kt)("li",{parentName:"ul"},"The script variable ",(0,o.kt)("inlineCode",{parentName:"li"},"Log::enable_remote_logging")," is set to ",(0,o.kt)("inlineCode",{parentName:"li"},"T"),".")),(0,o.kt)("p",null,"Note: you can spawn Zeek with ",(0,o.kt)("inlineCode",{parentName:"p"},"Log::enable_local_logging=F")," to avoid writing\nadditional local log files."),(0,o.kt)("p",null,"You can also spawn a Broker endpoint that is listening instead of connecting:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"# Spawn a Broker endpoint, listen on localhost:8888/tcp, and subscribe\n# to the topic `foo/bar`.\nvast import broker --listen --port=8888 --topic=foo/bar\n")),(0,o.kt)("p",null,"By default, VAST automatically subscribes to the topic ",(0,o.kt)("inlineCode",{parentName:"p"},"zeek/logs/")," because\nthis is where Zeek publishes log events. Use ",(0,o.kt)("inlineCode",{parentName:"p"},"--topic")," to set a different topic."),(0,o.kt)("h3",{id:"suricata"},"Suricata"),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"import suricata")," command format consumes ",(0,o.kt)("a",{parentName:"p",href:"https://suricata.readthedocs.io/en/latest/output/eve/eve-json-output.html"},"EVE\nJSON"),"\nlogs from ",(0,o.kt)("a",{parentName:"p",href:"https://suricata-ids.org"},"Suricata"),". Eve JSON is Suricata's unified\nformat to log all types of activity as single stream of ",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON"},"line-delimited\nJSON"),"."),(0,o.kt)("p",null,'The Suricata "format" is a technically a JSON format, with a hard-coded\n',(0,o.kt)("a",{parentName:"p",href:"#map-events-to-schemas"},"selector")," that maps the value of the\n",(0,o.kt)("inlineCode",{parentName:"p"},"event_type")," field to the prefix ",(0,o.kt)("inlineCode",{parentName:"p"},"suricata"),"."),(0,o.kt)("p",null,"Here's a Suricata ",(0,o.kt)("inlineCode",{parentName:"p"},"eve.log")," example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{"timestamp":"2011-08-12T14:52:57.716360+0200","flow_id":1031464864740687,"pcap_cnt":83,"event_type":"alert","src_ip":"147.32.84.165","src_port":1181,"dest_ip":"78.40.125.4","dest_port":6667,"proto":"TCP","alert":{"action":"allowed","gid":1,"signature_id":2017318,"rev":4,"signature":"ET CURRENT_EVENTS SUSPICIOUS IRC - PRIVMSG *.(exe|tar|tgz|zip)  download command","category":"Potentially Bad Traffic","severity":2},"flow":{"pkts_toserver":27,"pkts_toclient":35,"bytes_toserver":2302,"bytes_toclient":4520,"start":"2011-08-12T14:47:24.357711+0200"},"payload":"UFJJVk1TRyAjemFyYXNhNDggOiBzbXNzLmV4ZSAoMzY4KQ0K","payload_printable":"PRIVMSG #zarasa48 : smss.exe (368)\\r\\n","stream":0,"packet":"AB5J2xnDCAAntbcZCABFAABMGV5AAIAGLlyTIFSlTih9BASdGgvw0QvAxUWHdVAY+rCL4gAAUFJJVk1TRyAjemFyYXNhNDggOiBzbXNzLmV4ZSAoMzY4KQ0K","packet_info":{"linktype":1}}\n{"timestamp":"2011-08-12T14:55:22.154618+0200","flow_id":2247896271051770,"pcap_cnt":775,"event_type":"dns","src_ip":"147.32.84.165","src_port":1141,"dest_ip":"147.32.80.9","dest_port":53,"proto":"UDP","dns":{"type":"query","id":553,"rrname":"irc.freenode.net","rrtype":"A","tx_id":0}}\n{"timestamp":"2011-08-12T16:59:22.181050+0200","flow_id":472067367468746,"pcap_cnt":25767,"event_type":"fileinfo","src_ip":"74.207.254.18","src_port":80,"dest_ip":"147.32.84.165","dest_port":1046,"proto":"TCP","http":{"hostname":"www.nmap.org","url":"/","http_user_agent":"Mozilla/4.0 (compatible)","http_content_type":"text/html","http_method":"GET","protocol":"HTTP/1.1","status":301,"redirect":"http://nmap.org/","length":301},"app_proto":"http","fileinfo":{"filename":"/","magic":"HTML document, ASCII text","gaps":false,"state":"CLOSED","md5":"70041821acf87389e40ddcb092004184","sha1":"10395ab3566395ca050232d2c1a0dbad69eb5fd2","sha256":"2e4c462b3424afcc04f43429d5f001e4ef9a28143bfeefb9af2254b4df3a7c1a","stored":true,"file_id":1,"size":301,"tx_id":0}}\n')),(0,o.kt)("p",null,"Import the log as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import suricata < eve.log\n")),(0,o.kt)("p",null,"Instead of writing to a file, Suricata can also log to a UNIX domain socket that\nVAST reads from. This requires the following settings in your ",(0,o.kt)("inlineCode",{parentName:"p"},"suricata.yaml"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"outputs:\n  - eve-log:\n    enabled: yes\n    filetype: unix_stream\n    filename: eve.sock\n")),(0,o.kt)("p",null,"To import from a UNIX domain socket, combine netcat with a ",(0,o.kt)("inlineCode",{parentName:"p"},"vast import"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"nc -vlkU eve.sock | vast import suricata\n")),(0,o.kt)("h3",{id:"netflow"},"NetFlow"),(0,o.kt)(r.ZP,{mdxType:"CommercialPlugin"}),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/NetFlow"},"NetFlow")," is suite of protocols for\ncomputing and relaying flow-level statistics. An ",(0,o.kt)("em",{parentName:"p"},"exporter"),", such as a router or\nswitch, aggregates packets into flow records and sends them to a ",(0,o.kt)("em",{parentName:"p"},"collector"),"."),(0,o.kt)("admonition",{title:"Supported Versions",type:"note"},(0,o.kt)("p",{parentName:"admonition"},"VAST has native support for NetFlow ",(0,o.kt)("strong",{parentName:"p"},"v5"),", ",(0,o.kt)("strong",{parentName:"p"},"v9"),", and ",(0,o.kt)("strong",{parentName:"p"},"IPFIX"),". We have ",(0,o.kt)("a",{parentName:"p",href:"https://tenzir.com/blog/flexible-netflow-for-flexible-security-analytics/"},"a\nblog post")," about how we implement ",(0,o.kt)("em",{parentName:"p"},"Flexible NetFlow"),". For\nIPFIX we support Private Enterprise Numbers 3054 (IXIA IxFlow) and 29305\n(Bidirectional Flow Export) are supported. Please contact us if you require\nsupport for additional Private Enterprise Numbers.")),(0,o.kt)("p",null,"VAST can either act as collector or parse binary NetFlow data on standard input.\nThe NetFlow version is automatically identified at runtime, and mixing multiple\nversions (e.g., from multiple export devices) is possible."),(0,o.kt)("p",null,"To spin up a VAST client as NetFlow a collector, use the ",(0,o.kt)("inlineCode",{parentName:"p"},"vast import netflow"),"\ncommand:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import -l :2055/tcp netflow\n")),(0,o.kt)("p",null,"A commonly used NetFlow collector is ",(0,o.kt)("inlineCode",{parentName:"p"},"nfcapd"),", which writes NetFlow\nmessages into framed files. To replay from ",(0,o.kt)("inlineCode",{parentName:"p"},"nfcapd")," you can use ",(0,o.kt)("inlineCode",{parentName:"p"},"nfreplay"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import -l :9995/udp netflow\nnfreplay < path/to/capture.nfcapd # Exports all records to 127.0.0.1:9995\n")),(0,o.kt)("p",null,"Because VAST behaves like any other UNIX tool, it can also import NetFlow\nmessages from files or standard input directly:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"# From file\nvast import -r path/to/netflow.bin netflow\n\n# Pipe multiple files at once\ncat path/to/*.bin | vast import netflow\n")),(0,o.kt)("h3",{id:"pcap"},"PCAP"),(0,o.kt)("p",null,"VAST supports reading and writing ",(0,o.kt)("a",{parentName:"p",href:"http://www.tcpdump.org"},"PCAP")," traces via\n",(0,o.kt)("inlineCode",{parentName:"p"},"libpcap"),". On the read path, VAST can either acquire packets from a trace file\nor in ",(0,o.kt)("em",{parentName:"p"},"live mode")," from a network interface."),(0,o.kt)("p",null,"While decapsulating packets, VAST extracts\n",(0,o.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/IEEE_802.1Q"},"802.1Q")," VLAN tags into the nested\n",(0,o.kt)("inlineCode",{parentName:"p"},"vlan")," record, consisting of an ",(0,o.kt)("inlineCode",{parentName:"p"},"outer")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"inner")," field for the respective\ntags. The value of the VLAN tag corresponds to the 12-bit VLAN identifier (VID).\nSpecial values include ",(0,o.kt)("inlineCode",{parentName:"p"},"0")," (frame does not carry a VLAN ID) and ",(0,o.kt)("inlineCode",{parentName:"p"},"0xFFF"),"\n(reserved value; sometimes wildcard match)."),(0,o.kt)("p",null,"In addition, VAST computes the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/corelight/community-id-spec"},"Community\nID")," per packet to support\npivoting from other log data. The packet record contains a field ",(0,o.kt)("inlineCode",{parentName:"p"},"community_id"),"\nthat represents the string representation of the Community ID, e.g.,\n",(0,o.kt)("inlineCode",{parentName:"p"},"1:wCb3OG7yAFWelaUydu0D+125CLM="),". If you prefer to not have the Community ID in\nyour data, add the option ",(0,o.kt)("inlineCode",{parentName:"p"},"--disable-community-id")," to the ",(0,o.kt)("inlineCode",{parentName:"p"},"pcap")," command."),(0,o.kt)("p",null,"To ingest a PCAP file ",(0,o.kt)("inlineCode",{parentName:"p"},"input.trace"),", pass it to the ",(0,o.kt)("inlineCode",{parentName:"p"},"pcap")," command on standard\ninput:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import pcap < input.trace\n")),(0,o.kt)("p",null,"You can also acquire packets by listening on an interface:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import pcap -i eth0\n")),(0,o.kt)("h4",{id:"real-world-traffic-replay"},"Real-World Traffic Replay"),(0,o.kt)("p",null,'When reading PCAP data from a trace, VAST processes packets directly one after\nanother. This differs from live packet capturing where there exists natural\ninter-packet arrival times, according to the network traffic pattern. To emulate\n"real-world" trace replay, VAST supports a ',(0,o.kt)("em",{parentName:"p"},"pseudo-realtime")," mode, which works\nby introducing inter-packet delays according to the difference between subsquent\npacket timestamps."),(0,o.kt)("p",null,"The option ",(0,o.kt)("inlineCode",{parentName:"p"},"--pseudo-realtime"),"/",(0,o.kt)("inlineCode",{parentName:"p"},"-p")," takes a positive integer ",(0,o.kt)("em",{parentName:"p"},"c")," to delay\npackets by a factor of ",(0,o.kt)("em",{parentName:"p"},"1/c"),". For example, if the first packet arrives at time\n",(0,o.kt)("em",{parentName:"p"},"t0")," and the next packet at time ",(0,o.kt)("em",{parentName:"p"},"t1"),", then VAST would sleep for time\n",(0,o.kt)("em",{parentName:"p"},"(t1 - t0)/c")," before releasing the second packet. Intuitively, the larger ",(0,o.kt)("em",{parentName:"p"},"c"),"\ngets, the faster the replay takes place."),(0,o.kt)("p",null,"For example, to replay packets as if they arrived in realtime, use ",(0,o.kt)("inlineCode",{parentName:"p"},"-p 1"),". To\nreplay packets twice as fast as they arrived on the NIC, use ",(0,o.kt)("inlineCode",{parentName:"p"},"-p 2"),"."),(0,o.kt)("h4",{id:"flow-management"},"Flow Management"),(0,o.kt)("p",null,'The PCAP plugin has a few tuning knows for controlling storage of connection\ndata. Naive approaches, such as sampling or using a "snapshot" (',(0,o.kt)("inlineCode",{parentName:"p"},"tcpdump -s"),")\nmake transport-level analysis impractical due to an incomplete byte stream.\nInspired by the ",(0,o.kt)("a",{parentName:"p",href:"http://www.icir.org/vern/papers/time-machine-sigcomm08.pdf"},"Time Machine"),", the PCAP plugin supports recording only the\nfirst ",(0,o.kt)("em",{parentName:"p"},"N")," bytes of a connection (the ",(0,o.kt)("em",{parentName:"p"},"cutoff"),") and skipping the bulk of the flow\ndata. This allows for recording most connections in their entirety while\nachieving a massive space reduction by forgoing the heavy tail of the traffic\ndistribution."),(0,o.kt)("p",null,"To record only the first 1,024 bytes every connection, pass ",(0,o.kt)("inlineCode",{parentName:"p"},"-c 1024")," as option.\nNot that the cut-off is ",(0,o.kt)("em",{parentName:"p"},"bi-directional"),", i.e., it applies to both the\noriginator and responder TCP streams and a flow gets evicted only after both\nsides have reached their cutoff value."),(0,o.kt)("p",null,"In addition to cutoff configuration, the PCAP plugin has a few other tuning\nparameters. VAST keeps a flow table with per-connection state. The\n",(0,o.kt)("inlineCode",{parentName:"p"},"--max-flows"),"/",(0,o.kt)("inlineCode",{parentName:"p"},"-m")," option specifies an upper bound on the flow table size in\nnumber of connections. After a certain amount of inactivity of a flow,\nthe corresponding state expires. The option ",(0,o.kt)("inlineCode",{parentName:"p"},"--max-flow-age"),"/",(0,o.kt)("inlineCode",{parentName:"p"},"-a")," controls this\ntimeout value. Finally, the frequency of when the flow table expires entries\ncan be controlled via ",(0,o.kt)("inlineCode",{parentName:"p"},"--flow-expiry"),"/",(0,o.kt)("inlineCode",{parentName:"p"},"-e"),"."),(0,o.kt)("h3",{id:"argus"},"Argus"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://qosient.com/argus/index.shtml"},"Argus")," is an open-source flow monitor\nthat computes a variety of connection statistics. The UNIX tool ",(0,o.kt)("inlineCode",{parentName:"p"},"argus"),"\nprocesses either PCAP or NetFlow data and generates binary output. The companion\nutility ",(0,o.kt)("inlineCode",{parentName:"p"},"ra")," transforms this binary output into a textual form that VAST can\nparse."),(0,o.kt)("p",null,"Ingesting Argus data involves the following steps:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Read PCAP or NetFlow data with ",(0,o.kt)("inlineCode",{parentName:"li"},"argus")),(0,o.kt)("li",{parentName:"ol"},"Convert the binary Argus data into CSV with ",(0,o.kt)("inlineCode",{parentName:"li"},"ra")),(0,o.kt)("li",{parentName:"ol"},"Pipe the ",(0,o.kt)("inlineCode",{parentName:"li"},"ra")," output to ",(0,o.kt)("inlineCode",{parentName:"li"},"vast"))),(0,o.kt)("h4",{id:"read-network-data"},"Read network data"),(0,o.kt)("p",null,"To read a PCAP file, simply pass a file via ",(0,o.kt)("inlineCode",{parentName:"p"},"-r"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"argus -r trace\n")),(0,o.kt)("p",null,"To read from standard input, use ",(0,o.kt)("inlineCode",{parentName:"p"},"-r -"),". Similarly, to write to standard\noutput, use ",(0,o.kt)("inlineCode",{parentName:"p"},"-w -"),"."),(0,o.kt)("h4",{id:"convert-argus-to-csv"},"Convert Argus to CSV"),(0,o.kt)("p",null,"Converting ",(0,o.kt)("inlineCode",{parentName:"p"},"argus")," output to CSV requires the following flags:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"-c ,")," to enable CSV mode"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"-L0")," to print a header with field names once"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"-n")," suppress port nubmer to service conversions")),(0,o.kt)("p",null,"The first column contains the timestamp, but unfortunately the default format\ndoesn't contain dates. Changing the timestamp format requires passing a\ncustom configuration file via ",(0,o.kt)("inlineCode",{parentName:"p"},"-F ra.conf")," with the following contents:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'RA_TIME_FORMAT="%y-%m-%d+%T.%f"\n')),(0,o.kt)("p",null,"Finally, the ",(0,o.kt)("inlineCode",{parentName:"p"},"-s +a,b,c,...")," flag includes list of field names that should be\nappended after the default fields. Consult the manpage of ",(0,o.kt)("inlineCode",{parentName:"p"},"ra")," under the ",(0,o.kt)("inlineCode",{parentName:"p"},"-s"),"\nsection for valid field names."),(0,o.kt)("p",null,"Put together, the following example generates valid CSV output for a PCAP file\ncalled ",(0,o.kt)("inlineCode",{parentName:"p"},"trace.pcap"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"argus -r trace.pcap -w - |\n  ra -F ra.conf -L0 -c , -n -s +spkts,dpkts,load,pcr\n")),(0,o.kt)("p",null,"This generates the following output:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"StartTime,Flgs,Proto,SrcAddr,Sport,Dir,DstAddr,Dport,TotPkts,TotBytes,State,SrcPkts,DstPkts,Load,PCRatio\n09-11-18+09:00:03.914398, e        ,udp,192.168.1.1,626,   ->,224.0.0.1,626,1,75,INT,1,0,0.000000,-0.000000\n09-11-18+09:00:20.093410, e        ,lldp,00:22:2d:81:db:10,0,   ->,01:80:c2:00:00:0e,0,1,118,INT,1,0,0.000000,-0.000000\n09-11-18+09:00:21.486288, e        ,arp,192.168.1.102,,  who,192.168.1.1,,2,106,CON,1,1,0.000000,-0.000000\n09-11-18+09:00:21.486539, e        ,udp,192.168.1.102,68,  <->,192.168.1.1,67,2,689,CON,1,1,0.000000,-0.000000\n09-11-18+09:00:33.914396, e        ,udp,192.168.1.1,626,   ->,224.0.0.1,626,1,75,REQ,1,0,0.000000,-0.000000\n09-11-18+09:00:50.208499, e        ,lldp,00:22:2d:81:db:10,0,   ->,01:80:c2:00:00:0e,0,1,118,REQ,1,0,0.000000,-0.000000\n09-11-18+09:01:03.914408, e        ,udp,192.168.1.1,626,   ->,224.0.0.1,626,1,75,REQ,1,0,0.000000,-0.000000\n09-11-18+09:01:20.323835, e        ,lldp,00:22:2d:81:db:10,0,   ->,01:80:c2:00:00:0e,0,1,118,REQ,1,0,0.000000,-0.000000\n09-11-18+09:01:33.914414, e        ,udp,192.168.1.1,626,   ->,224.0.0.1,626,1,75,REQ,1,0,0.000000,-0.000000\n")),(0,o.kt)("h4",{id:"ingest-argus-csv"},"Ingest Argus CSV"),(0,o.kt)("p",null,"Since VAST has ",(0,o.kt)("a",{parentName:"p",href:"#CSV"},"native CSV support"),", ingesting Argus CSV output only\nrequires an adequate schema. VAST already ships with an argus schema containing a\ntype ",(0,o.kt)("inlineCode",{parentName:"p"},"argus.record")," that covers all fields from the ",(0,o.kt)("inlineCode",{parentName:"p"},"ra")," man page."),(0,o.kt)("p",null,"The following command imports a file ",(0,o.kt)("inlineCode",{parentName:"p"},"argus.csv"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import -t argus.record csv < argus.csv\n")),(0,o.kt)("p",null,"Alternatively, this command pipeline processes a PCAP trace without\nintermediate file and ships sends the data directory to VAST:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"argus -r trace.pcap -w - |\n  ra -F ra.conf -L0 -c , -n -s +spkts,dpkts,load,pcr |\n  vast import -t argus.record csv\n")),(0,o.kt)("h2",{id:"discard-events-from-a-data-source"},"Discard events from a data source"),(0,o.kt)("p",null,"To reduce the volume of a data source or to filter out unwanted content, you can\nprovide a filter expression to the ",(0,o.kt)("inlineCode",{parentName:"p"},"import")," command."),(0,o.kt)("p",null,"For example, you might want to import Suricata Eve JSON, but skip over all\nevents of type ",(0,o.kt)("inlineCode",{parentName:"p"},"suricata.stats"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import suricata '#type != \"suricata.stats\"' < path/to/eve.json\n")),(0,o.kt)("p",null,"See the ",(0,o.kt)("a",{parentName:"p",href:"/docs/understand-vast/query-language/"},"query language documentation")," to\nlearn more about how to express filters."),(0,o.kt)("h2",{id:"infer-a-schema-automatically"},"Infer a schema automatically"),(0,o.kt)("admonition",{title:"Auto-inference underway",type:"note"},(0,o.kt)("p",{parentName:"admonition"},"We have planned to make big improvements to the schema management. Most notably,\nwriting a schema will be optional in the future, i.e., only needed when tuning\ndata semantics.")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"infer")," command attempts to deduce a schema, given a sample of data. For\nexample, consider this JSON data:"),(0,o.kt)(i.ZP,{mdxType:"MissingDocumentation"}),(0,o.kt)("p",null,"Run ",(0,o.kt)("inlineCode",{parentName:"p"},"head -1 data.json | vast infer")," to print schema that you can paste into a\nmodule."),(0,o.kt)(i.ZP,{mdxType:"MissingDocumentation"}),(0,o.kt)("p",null,"The idea is that ",(0,o.kt)("inlineCode",{parentName:"p"},"infer")," jump-starts the schema writing process by providing a\nreasonable blueprint. You still need to provide the right name for the type and\nperform adjustments, such as replacing some generic types with more semantic\naliases, e.g., using the ",(0,o.kt)("inlineCode",{parentName:"p"},"timstamp")," alias instead of type ",(0,o.kt)("inlineCode",{parentName:"p"},"time")," to designate\nthe event timestamp."),(0,o.kt)("h2",{id:"write-a-schema-manually"},"Write a schema manually"),(0,o.kt)("p",null,"If VAST does not ship with a ",(0,o.kt)("a",{parentName:"p",href:"/docs/understand-vast/data-model/modules"},"module")," for your data out of the box,\nor the inference is not good enough for your use case regarding type semantics\nor performance, you can easily write one yourself."),(0,o.kt)("p",null,"A schema is a record type with a name so that VAST can\nrepresent it as a table internally. You would write a schema manually or extend\nan existing schema if your goal is tuning type semantics and performance. For\nexample, if you have a field of type ",(0,o.kt)("inlineCode",{parentName:"p"},"string")," that only holds IP addresses, you\ncan upgrade it to type ",(0,o.kt)("inlineCode",{parentName:"p"},"addr")," and enjoy the benefits of richer query\nexpressions, e.g., top-k prefix search. Or if you onboard a new data source, you\ncan ship a schema along with ",(0,o.kt)("a",{parentName:"p",href:"/docs/understand-vast/data-model/taxonomies#concepts"},"concept")," mappings for a deeper\nintegration."),(0,o.kt)("p",null,"You write a schema (and potentially accompanying types, concepts, and models) in\na ",(0,o.kt)("a",{parentName:"p",href:"/docs/understand-vast/data-model/modules"},"module"),"."),(0,o.kt)("p",null,"Let's write one from scratch, for a tiny dummy data source called ",(0,o.kt)("em",{parentName:"p"},"foo")," that\nproduces CSV events of this shape:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-csv"},"date,target,message\n2022-05-17,10.0.0.1,foo\n2022-05-18,10.0.0.2,bar\n2022-05-18,10.0.0.3,bar\n")),(0,o.kt)("p",null,"The corresponding schema type looks like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"message:\n  record:\n    - date: time\n    - target: addr\n    - message: msg\n")),(0,o.kt)("p",null,"You can embed this type definition in a dedicated ",(0,o.kt)("inlineCode",{parentName:"p"},"foo")," module:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"module: foo\ntypes:\n  message:\n    record:\n      - date: time\n      - target: addr\n      - message: msg\n")),(0,o.kt)("p",null,"Now that you have a new module, you can choose to deploy it at the client or\nthe server. When a VAST server starts, it will send a copy of its local schemas\nto the client. If the client has a schema for the same type, it will override\nthe server version. We recommend deploying the module at the server when all\nclients should see the contained schemas, and at the client when the scope is\nlocal. The diagram below illustrates the initial handshake:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Schema Transfer",src:a(91463).Z+"#gh-light-mode-only",width:"1448",height:"486"}),"\n",(0,o.kt)("img",{alt:"Schema Transfer",src:a(68189).Z+"#gh-dark-mode-only",width:"1448",height:"486"})),(0,o.kt)("p",null,"Regardless of where you deploy the module, the procedure is the same at client\nand server: place the module in an existing module directory, such as\n",(0,o.kt)("inlineCode",{parentName:"p"},"/etc/vast/modules"),", or tell VAST in your ",(0,o.kt)("inlineCode",{parentName:"p"},"vast.yaml")," configuration file where\nto look for additional modules via the ",(0,o.kt)("inlineCode",{parentName:"p"},"module-dirs")," key:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"vast:\n  module-dirs:\n    - path/to/modules\n")),(0,o.kt)("p",null,"At the server, restart VAST and you're ready to go. Or just spin up a new client\nand ingest the CSV with richer typing:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"vast import csv < foo.csv\n")),(0,o.kt)("h2",{id:"map-events-to-schemas"},"Map events to schemas"),(0,o.kt)("p",null,"For some input formats, such as JSON and CSV, VAST requires an existing schema\nto find the corresponding type definition and use higher-level types."),(0,o.kt)("p",null,"There exist two ways to tell VAST how to map events to schemas:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Field Matching"),": by default, VAST checks every new record whether there\nexists a corresponding schema where the record fields match. If found, VAST\nautomatically assigns the matching schema."),(0,o.kt)("p",{parentName:"li"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"--type=PREFIX"),' option makes it possible to restrict the set of candidate\nschemas to type names with a given prefix, in case there exist multiple\nschemas with identical field names. "Prefix" here means up to a dot delimiter\nor a full type name, e.g., ',(0,o.kt)("inlineCode",{parentName:"p"},"suricata")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"suricata.dns")," are valid prefixes,\nbut neither ",(0,o.kt)("inlineCode",{parentName:"p"},"suricat")," nor ",(0,o.kt)("inlineCode",{parentName:"p"},"suricata.d"),"."),(0,o.kt)("admonition",{parentName:"li",title:"Performance Boost",type:"info"},(0,o.kt)("p",{parentName:"admonition"},"In case the prefix specified by ",(0,o.kt)("inlineCode",{parentName:"p"},"--type")," yields ",(0,o.kt)("em",{parentName:"p"},"exactly one")," possible\ncandidate schema, VAST can operate substantially faster. The reason is that\nVAST disambiguates multiple schemas by comparing their normalized\nrepresentation, which works by computing hash of the list of sorted field\nnames and comparing it to the hash of the candidate types."))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Selector Specification"),": some events have a dedicated field to indicate\nthe type name of a particular event. For example, Suricata EVE JSON records\nhave an ",(0,o.kt)("inlineCode",{parentName:"p"},"event_type")," field that contains ",(0,o.kt)("inlineCode",{parentName:"p"},"flow"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"dns"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"smb"),", etc., to\nsignal what object structure to expect."),(0,o.kt)("p",{parentName:"li"},"To designate a selector field, use the ",(0,o.kt)("inlineCode",{parentName:"p"},"--selector=FIELD:PREFIX")," option to\nspecify a colon-separated field-name-to-schema-prefix mapping, e.g.,\n",(0,o.kt)("inlineCode",{parentName:"p"},"vast import json --selector=event_type:suricata")," reads the value from the\nfield ",(0,o.kt)("inlineCode",{parentName:"p"},"event_type")," and prefixes it with ",(0,o.kt)("inlineCode",{parentName:"p"},"suricata.")," to look for a\ncorresponding schema."))))}u.isMDXComponent=!0},14185:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ingest.dark-43f5333762fb93a4ed63a544d2ad0c3d.png"},22596:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ingest.light-a92e7149cce2dd14830f50bef4beb3d6.png"},68189:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/schema-transfer.dark-924e5529116843b98ce544e88e06718c.png"},91463:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/schema-transfer.light-374a21d62ac6eb9f0b663fa5a91d6bf5.png"}}]);